{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFQ3zuAP1Fv3YMr2dop3zT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugamDewan/Azure-Databricks-MovieLens-Pipeline/blob/main/MovieLens_Azure_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé¨ MovieLens Data Analysis Pipeline\n",
        "**Author:** Sugam Dewan\n",
        "**Date:** 2025-12-29\n",
        "**Tech Stack:** Azure Data Lake Gen2, Databricks (PySpark), Python\n",
        "\n",
        "## üìã Project Overview\n",
        "In this project, I built an end-to-end data engineering pipeline to analyze movie ratings. The goal was to ingest raw data from Azure Storage, transform it using Spark to derive insights, and visualize the top-rated movies.\n",
        "\n",
        "**Key Steps:**\n",
        "1. **Ingestion:** Secure connection to Azure Data Lake using SAS Tokens (Direct Access).\n",
        "2. **Extraction:** Handling compressed (zipped) raw data via shell integration.\n",
        "3. **Transformation:** Cleaning timestamps and joining relational datasets (Movies + Ratings).\n",
        "4. **Analysis:** Aggregating millions of ratings to identify the highest-rated films."
      ],
      "metadata": {
        "id": "oreaqZj8aKcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RwaEOCDaIp9"
      },
      "outputs": [],
      "source": [
        "# 1Ô∏è‚É£ Configuration & Security\n",
        "# Connection to Azure Data Lake Storage (ADLS) Gen2 via SAS Token.\n",
        "# Note: SAS Token is hidden for security in this public repository.\n",
        "\n",
        "storage_account_name = \"movielensanalysis\"\n",
        "sas_token = \"HIDDEN_FOR_SECURITY\"\n",
        "\n",
        "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"SAS\")\n",
        "spark.conf.set(f\"fs.azure.sas.token.provider.type.{storage_account_name}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
        "spark.conf.set(f\"fs.azure.sas.fixed.token.{storage_account_name}.dfs.core.windows.net\", sas_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2Ô∏è‚É£ Bronze Layer: Ingestion & Extraction\n",
        "# Logic to download the compressed zip from Azure, extract it locally, and re-upload raw CSVs.\n",
        "\n",
        "# Variables\n",
        "container = \"containerdatalake\"\n",
        "zip_filename = \"ml_latest_small.zip\"\n",
        "\n",
        "# Paths\n",
        "cloud_zip_path = f\"abfss://{container}@{storage_account_name}.dfs.core.windows.net/{zip_filename}\"\n",
        "local_zip_path = f\"/tmp/{zip_filename}\"\n",
        "local_extract_path = \"/tmp/movielens_extracted/ml-latest-small\" # Targeted extraction folder\n",
        "cloud_dest_path = f\"abfss://{container}@{storage_account_name}.dfs.core.windows.net/raw_data/\"\n",
        "\n",
        "# 1. Download\n",
        "dbutils.fs.cp(cloud_zip_path, f\"file:{local_zip_path}\")\n",
        "\n",
        "# 2. Extract (Shell Command Logic)\n",
        "# %sh\n",
        "# unzip -o /tmp/ml_latest_small.zip -d /tmp/movielens_extracted\n",
        "\n",
        "# 3. Upload Extracted Data\n",
        "dbutils.fs.cp(f\"file:{local_extract_path}\", cloud_dest_path, recurse=True)"
      ],
      "metadata": {
        "id": "T3vZ4r4maTf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3Ô∏è‚É£ Silver Layer: Data Loading & Cleaning\n",
        "from pyspark.sql.functions import from_unixtime, col, avg, count, desc\n",
        "\n",
        "# Define path to the now-extracted CSVs\n",
        "base_path = f\"abfss://{container}@{storage_account_name}.dfs.core.windows.net/raw_data\"\n",
        "\n",
        "# Load Movies\n",
        "df_movies = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(f\"{base_path}/movies.csv\")\n",
        "\n",
        "# Load Ratings\n",
        "df_ratings = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(f\"{base_path}/ratings.csv\")\n",
        "\n",
        "# Transform: Convert Timestamp to Date\n",
        "df_ratings_clean = df_ratings.withColumn(\"rating_date\", from_unixtime(col(\"timestamp\")).cast(\"date\"))\n",
        "\n",
        "display(df_ratings_clean.limit(5))"
      ],
      "metadata": {
        "id": "UZCCdKybaXX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4Ô∏è‚É£ Gold Layer: Analytical Transformation\n",
        "# Join datasets and aggregate to find top-rated movies.\n",
        "\n",
        "# Join Movies and Ratings\n",
        "df_joined = df_movies.join(df_ratings_clean, on=\"movieId\", how=\"inner\")\n",
        "\n",
        "# Aggregate: Avg Rating and Count Votes\n",
        "df_analysis = df_joined.groupBy(\"title\") \\\n",
        "    .agg(\n",
        "        avg(\"rating\").alias(\"average_rating\"),\n",
        "        count(\"rating\").alias(\"total_votes\")\n",
        "    )\n",
        "\n",
        "# Filter: Top Movies (>50 votes) sorted by Rating\n",
        "top_movies = df_analysis.filter(\"total_votes > 50\").orderBy(desc(\"average_rating\"))\n",
        "\n",
        "display(top_movies.limit(10))"
      ],
      "metadata": {
        "id": "nM6Q3HPXaaZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Visualization & Results\n",
        "*(See the attached chart image in the repository for the visual output)*\n",
        "\n",
        "**Insight:**\n",
        "The analysis identified classics such as *The Shawshank Redemption*, *The Godfather*, and *Fight Club* as the highest-rated movies with significant user engagement. The pipeline successfully processed user ratings to generate this leaderboard."
      ],
      "metadata": {
        "id": "p9A7-nm4aguw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Visualization (Recreated for Portfolio View)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# The results from our Spark Analysis (Hardcoded for demonstration since Azure is offline)\n",
        "data = {\n",
        "    'Title': ['Shawshank Redemption, The (1994)', 'Godfather, The (1972)', 'Fight Club (1999)', 'Godfather: Part II, The (1974)', 'Cool Hand Luke (1967)'],\n",
        "    'Average Rating': [4.42, 4.28, 4.27, 4.25, 4.24]\n",
        "}\n",
        "\n",
        "# Create a local Pandas DataFrame\n",
        "df_viz = pd.DataFrame(data)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(df_viz['Title'], df_viz['Average Rating'], color='#1f77b4')\n",
        "plt.xlabel('Movie Title')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Top 5 Rated Movies (Dataset Analysis Result)')\n",
        "plt.ylim(0, 5) # Set limit to 5 stars\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d1uvgoLAafHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}